{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "#import sklearn.preprocessing as pre\n",
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('ex1data2.txt',delimiter=',')\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1].reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X, mu=None, sigma=None):\n",
    "    \"\"\"Apply Standardization method to an unbiased array of features.\n",
    "    \n",
    "    The features will be rescaled so that theyâ€™ll have the properties\n",
    "    of a standard normal distribution with mean=0 and std=1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        Input array.\n",
    "        The input array must not include the bias column.\n",
    "        If `X` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``\n",
    "        before standardization.\n",
    "    mu : array_like, optional\n",
    "        The mean to be used in the Standardization algorithm.\n",
    "        If `mu` is not provided, it will be computed as the mean of `X`.\n",
    "    sigma : array_like, optional\n",
    "        The standard deviation to be used in the Standardization algorithm.\n",
    "        If `sigma` is not provided, it will be computed as the standard\n",
    "        deviation of `X`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    z : numpy.ndarray\n",
    "        The standard scores (z-scores) of the features\n",
    "        as an array of `numpy.float64`.\n",
    "    mu : numpy.ndarray\n",
    "        The features means used in Standardization algorithm\n",
    "        as an array of `numpy.float64`.\n",
    "    sigma : numpy.ndarray\n",
    "        The features standard deviations used in the Standardization algorithm\n",
    "        as an array of `numpy.float64`.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = [[2, 3],[4, 5],[6, 7]]\n",
    "    >>> print(normalize_features(x))\n",
    "    (array([[-1.22474487, -1.22474487],\n",
    "           [ 0.        ,  0.        ],\n",
    "           [ 1.22474487,  1.22474487]]), array([4., 5.]), array([1.63299316, 1.63299316]))\n",
    "    \n",
    "    >>> mu = [4., 5.]\n",
    "    >>> sigma = [1.63299316, 1.63299316]\n",
    "    >>> print(normalize_features(x,mu,sigma))\n",
    "    (array([[-1.22474487, -1.22474487],\n",
    "           [ 0.        ,  0.        ],\n",
    "           [ 1.22474487,  1.22474487]]), array([4., 5.]), array([1.63299316, 1.63299316]))\n",
    "    \"\"\"\n",
    "    if np.ndim(X) == 1:\n",
    "        X = np.reshape(X, (-1,1))\n",
    "        \n",
    "    mu = np.mean(X, axis=0) if mu is None else np.array(mu)\n",
    "    sigma = np.std(X, axis=0) if sigma is None else np.array(sigma)\n",
    "    Z = (np.array(X) - mu) / sigma\n",
    "    return Z, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Bias Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_bias_feature(X):\n",
    "    \"\"\"Insert a column filled with ones in front of an unbiased array of features.\n",
    "    \n",
    "    The new column is inserted at index ``0`` on axis ``1``.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        Input array.\n",
    "        The input array must not include the bias column.\n",
    "        If `X` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``\n",
    "        before the new column insertion.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Output array.\n",
    "        If `X` has ``(m,n)`` shape, the return value will have ``(m,n+1)``shape.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.array([[2,3],[4,5],[6,7]])\n",
    "    >>> insert_bias_feature(x)\n",
    "    array([[1, 2, 3],\n",
    "           [1, 4, 5],\n",
    "           [1, 6, 7]])\n",
    "     \n",
    "    >>> x = np.array([[2],[3],[4]])\n",
    "    >>> insert_bias_feature(x)\n",
    "    array([[1, 2],\n",
    "           [1, 3],\n",
    "           [1, 4]])\n",
    "     \n",
    "    >>> x = [2,3,4]\n",
    "    >>> insert_bias_feature(x)\n",
    "    array([[1, 2],\n",
    "           [1, 3],\n",
    "           [1, 4]])\n",
    "    \"\"\"\n",
    "    if np.ndim(X) == 1:\n",
    "        X = np.reshape(X, (-1,1))\n",
    "        \n",
    "    return np.insert(X,0,1,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_theta(shape, order='C'):\n",
    "    \"\"\"Return a new array of given shape, filled with `numpy.float64` zeros.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : int or sequence of ints\n",
    "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
    "    order : {'C', 'F'}, optional\n",
    "        Whether to store multidimensional data in C- or Fortran-contiguous\n",
    "        (row- or column-wise) order in memory.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Array of `numpy.float64` zeros with the given shape and order.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> initialize_theta(5)\n",
    "    array([0., 0., 0., 0., 0.])\n",
    "    \n",
    "    >>> initialize_theta((5,))\n",
    "    array([0., 0., 0., 0., 0.])\n",
    "    \n",
    "    >>> initialize_theta((2, 1))\n",
    "    array([[0.],\n",
    "           [0.]])\n",
    "    \n",
    "    >>> initialize_theta((2,2))\n",
    "    array([[0., 0.],\n",
    "           [0., 0.]])\n",
    "    \"\"\"\n",
    "    return np.zeros(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_loss(theta,X,y):\n",
    "    \"\"\"Compute linear regression cost from unbiased examples.\n",
    "    \n",
    "    The cost is the result of the Mean Squared Error computation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : array_like\n",
    "        Parameters (weights) of the model, including the bias parameter.\n",
    "        If `theta` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``.\n",
    "    X : array_like\n",
    "        Input examples.\n",
    "        The input array must not include the bias column.\n",
    "        If `X` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``.\n",
    "    y : array_like\n",
    "        Output examples.\n",
    "        If `y` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)```.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    J : numpy.float64\n",
    "        Cost value.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> t = [[0],[0]]\n",
    "    >>> x = [[6.1101], [5.5277], [8.5186], [7.0032], [5.8598]]\n",
    "    >>> y = [[17.592], [9.1302], [13.662], [11.854], [6.8233]]\n",
    "    >>> linear_loss(t,x,y)\n",
    "    76.656399893\n",
    "    \n",
    "    >>> t = [0,0]\n",
    "    >>> x = [6.1101, 5.5277, 8.5186, 7.0032, 5.8598]\n",
    "    >>> y = [17.592, 9.1302, 13.662, 11.854, 6.8233]\n",
    "    >>> linear_loss(t,x,y)\n",
    "    76.656399893\n",
    "    \"\"\"\n",
    "    if np.ndim(theta) == 1:\n",
    "        theta = np.reshape(theta,(-1,1))\n",
    "    if np.ndim(y) == 1:\n",
    "        y = np.reshape(y, (-1,1))\n",
    "        \n",
    "    X_biased = insert_bias_feature(X)\n",
    "    z = X_biased @ theta\n",
    "    J = np.sum(np.square(z - y)) / (2*len(y))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_gradient_descent(X,y,alpha,iterations):\n",
    "    \"\"\"Minimize linear loss from unbiased examples using gradient descent method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        Input examples.\n",
    "        The input array must not include the bias column.\n",
    "        If `X` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``.\n",
    "    y : array_like\n",
    "        Output examples.\n",
    "        If `y` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``.\n",
    "    alpha: float\n",
    "        The learning rate.\n",
    "        Usually choosen from: ``[0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]``.\n",
    "    iterations: int\n",
    "        The number of iterations of the gradient descent algorithm.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    theta : numpy.ndarray\n",
    "        The model's parameters (weights).\n",
    "    costs : numpy.ndarray\n",
    "        An array of cost values per iteration.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = [[6.1101], [5.5277], [8.5186], [7.0032], [5.8598]]\n",
    "    >>> y = [[17.592], [9.1302], [13.662], [11.854], [6.8233]]\n",
    "    >>> a = 0.01\n",
    "    >>> i = 3\n",
    "    >>> print(linear_gradient_descent(x,y,a,i))\n",
    "    (array([[0.21793241],\n",
    "           [1.45965607]]), array([26.87250936, 12.21653968,  7.90190872]))\n",
    "    \n",
    "    >>> x = [6.1101, 5.5277, 8.5186, 7.0032, 5.8598]\n",
    "    >>> y = [17.592, 9.1302, 13.662, 11.854, 6.8233]\n",
    "    >>> linear_gradient_descent(x,y,a,i)\n",
    "    (array([[0.21793241],\n",
    "           [1.45965607]]), array([26.87250936, 12.21653968,  7.90190872]))\n",
    "    \"\"\"\n",
    "    if np.ndim(y) == 1:\n",
    "        y = np.reshape(y, (-1,1))\n",
    "        \n",
    "    X_biased = insert_bias_feature(X)\n",
    "    m, n = X_biased.shape\n",
    "    theta = initialize_theta((n,1))\n",
    "    costs = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        z = X_biased @ theta\n",
    "        D = X_biased.T @ (z - y) / len(y)\n",
    "        theta -= alpha * D\n",
    "        costs[i] = linear_loss(theta,X,y)\n",
    "    return theta, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1137f5518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_gradient_descent(X,y,alphas,iterations):\n",
    "    X_norm, mu, sigma = normalize_features(X)\n",
    "    colors = plt.cm.viridis(np.linspace(0,1,len(alphas)))\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        theta, costs = linear_gradient_descent(X_norm,y,alpha,iterations)\n",
    "        plt.plot(costs,'-g',label=rf'$\\alpha = {alpha}$',color=colors[i]);\n",
    "        \n",
    "    plt.legend();\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Cost');\n",
    "    \n",
    "plot_gradient_descent(X,y,alphas=[0.01,0.03,0.1,0.3,1],iterations=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated price of a house with 1650 square feet and 3 bedrooms is $293081.46\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(X,y,xs):\n",
    "    X_norm, mu, sigma = normalize_features(X)\n",
    "    theta, _ = linear_gradient_descent(X_norm,y,alpha=1,iterations=400)\n",
    "    xs_norm, _, _ = normalize_features(xs, mu=mu, sigma=sigma)\n",
    "    xs_biased = insert_bias_feature(xs_norm)\n",
    "    ys = xs_biased @ theta\n",
    "    print(f'The estimated price of a house with {xs[0,0]} square feet and {xs[0,1]} bedrooms is ${ys[0,0]:.2f}')\n",
    "    \n",
    "make_predictions(X,y,xs=np.array([[1650,3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equations(X,y):\n",
    "    \"\"\"Solves the linear least squares for unbiased examples,\n",
    "    using the derivation of the normal equations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        Input examples.\n",
    "        The input array must not include the bias column.\n",
    "        If `X` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``.\n",
    "    y : array_like\n",
    "        Output examples.\n",
    "        If `y` is a 1-D array of shape ``(m,)``, it will be reshaped to ``(m,1)``.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    theta : numpy.ndarray\n",
    "        The model's parameters (weights).\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = [[6.1101], [5.5277], [8.5186], [7.0032], [5.8598]]\n",
    "    >>> y = [[17.592], [9.1302], [13.662], [11.854], [6.8233]]\n",
    "    >>> normal_equations(x,y)\n",
    "    array([[3.47007754],\n",
    "           [1.26323047]])\n",
    "    \"\"\"\n",
    "    X_biased = insert_bias_feature(X)\n",
    "    theta = np.linalg.pinv(X_biased.T @ X_biased) @ X_biased.T @ y\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated price of a house with 1650 square feet and 3 bedrooms is $293081.46\n"
     ]
    }
   ],
   "source": [
    "def make_predictions_with_normal_equations(X,y,xs):\n",
    "    theta = normal_equations(X,y)\n",
    "    xs_biased = insert_bias_feature(xs)\n",
    "    ys = xs_biased @ theta\n",
    "    print(f'The estimated price of a house with {xs[0,0]} square feet and {xs[0,1]} bedrooms is ${ys[0,0]:.2f}')\n",
    "    \n",
    "make_predictions_with_normal_equations(X,y,xs=np.array([[1650,3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=34)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the file name (required)\n",
    "__file__ = 'ex1_multi.ipynb'\n",
    "\n",
    "# add ipython magics\n",
    "import ipytest.magics\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......                                                                                                                                                                                              [100%]\n",
      "7 passed in 0.11 seconds\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean] -qq -v\n",
    "\n",
    "def test_insert_bias_feature():\n",
    "    ipytest.assert_equals(insert_bias_feature([[2,3], [4,5], [6,7]]),\n",
    "                          np.array([[1, 2, 3], [1, 4, 5], [1, 6, 7]]))\n",
    "    ipytest.assert_equals(insert_bias_feature(np.array([[2],[3],[4]])),\n",
    "                          np.array([[1, 2], [1, 3], [1, 4]]))\n",
    "    ipytest.assert_equals(insert_bias_feature([2,3,4]),\n",
    "                          np.array([[1, 2], [1, 3], [1, 4]]))\n",
    "\n",
    "def test_initialize_theta():\n",
    "    ipytest.assert_equals(initialize_theta(5), np.array([0., 0., 0., 0., 0.]))\n",
    "    ipytest.assert_equals(initialize_theta((5,)), np.array([0., 0., 0., 0., 0.]))\n",
    "    ipytest.assert_equals(initialize_theta((2, 1)), np.array([[0.], [0.]]))\n",
    "    ipytest.assert_equals(initialize_theta((2,2)), np.array([[0., 0.], [0., 0.]]))\n",
    "    \n",
    "def test_linear_loss():\n",
    "    ipytest.assert_equals(linear_loss(\n",
    "        theta=[[0],[0]],\n",
    "        X=[[6.1101], [5.5277], [8.5186], [7.0032], [5.8598]],\n",
    "        y=[[17.592], [9.1302], [13.662], [11.854], [6.8233]]), 76.656399893)\n",
    "    ipytest.assert_equals(linear_loss(\n",
    "        theta=[0,0],\n",
    "        X=[6.1101, 5.5277, 8.5186, 7.0032, 5.8598],\n",
    "        y=[17.592, 9.1302, 13.662, 11.854, 6.8233]), 76.656399893)\n",
    "\n",
    "def test_normalize_features():\n",
    "    a1 = np.array([[1,2,3],[4,3,2],[2,3,4],[3,2,1]])\n",
    "    mu1 = np.array([2.5, 2.5, 2.5])\n",
    "    sigma1 = np.array([1.11803399, 0.5, 1.11803399])\n",
    "    a2 = np.array([[-1.34164079, -1., 0.4472136],\n",
    "                [1.34164079, 1., -0.4472136],\n",
    "                [-0.4472136, 1., 1.34164079],\n",
    "                [0.4472136, -1., -1.34164079]])\n",
    "    a3, mu2, sigma2 = normalize_features(a1)\n",
    "    ipytest.assert_equals(a3, a2)\n",
    "    ipytest.assert_equals(mu2, mu1)\n",
    "    ipytest.assert_equals(sigma2, sigma1)\n",
    "    \n",
    "def test_normalize_features_with_parameters():\n",
    "    a1 = np.array([[1,2,3],[4,3,2],[2,3,4],[3,2,1]])\n",
    "    mu1 = np.array([2.5, 2.5, 2.5])\n",
    "    sigma1 = np.array([1.11803399, 0.5, 1.11803399])\n",
    "    a2 = np.array([[-1.34164079, -1., 0.4472136],\n",
    "                [1.34164079, 1., -0.4472136],\n",
    "                [-0.4472136, 1., 1.34164079],\n",
    "                [0.4472136, -1., -1.34164079]])\n",
    "    a3, mu2, sigma2 = normalize_features(a1, mu=mu1, sigma=sigma1)\n",
    "    ipytest.assert_equals(a3, a2)\n",
    "    ipytest.assert_equals(mu2, mu1)\n",
    "    ipytest.assert_equals(sigma2, sigma1)\n",
    "    \n",
    "def test_linear_gradient_descent():\n",
    "    theta, costs = linear_gradient_descent(\n",
    "        X=[[6.1101], [5.5277], [8.5186], [7.0032], [5.8598]],\n",
    "        y=[[17.592], [9.1302], [13.662], [11.854], [6.8233]],\n",
    "        alpha=0.01, iterations=5)\n",
    "    ipytest.assert_equals(theta, np.array([[0.2484605],[1.65525105]]))\n",
    "    ipytest.assert_equals(costs, np.array([26.87250936, 12.21653968, 7.90190872, 6.63167333, 6.25768018]))\n",
    "    \n",
    "    theta, costs = linear_gradient_descent(\n",
    "        X=[6.1101, 5.5277, 8.5186, 7.0032, 5.8598],\n",
    "        y=[17.592, 9.1302, 13.662, 11.854, 6.8233],\n",
    "        alpha=0.01, iterations=5)\n",
    "    ipytest.assert_equals(theta, np.array([[0.2484605],[1.65525105]]))\n",
    "    ipytest.assert_equals(costs, np.array([26.87250936, 12.21653968, 7.90190872, 6.63167333, 6.25768018]))\n",
    "    \n",
    "def test_normal_equations():\n",
    "    X = [[6.1101], [5.5277], [8.5186], [7.0032], [5.8598]]\n",
    "    y = [[17.592], [9.1302], [13.662], [11.854], [6.8233]]\n",
    "    ipytest.assert_equals(normal_equations(X,y),\n",
    "                         np.array([[3.47007754],[1.26323047]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
