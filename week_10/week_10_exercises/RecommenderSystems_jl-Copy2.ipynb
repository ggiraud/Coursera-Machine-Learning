{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.RecommenderSystems"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module RecommenderSystems\n",
    "\n",
    "using Distributions: Normal, mean, MvNormal\n",
    "using LinearAlgebra: dot\n",
    "using Random: shuffle, GLOBAL_RNG\n",
    "using SharedArrays: SharedArray\n",
    "using Distributed#: @distributed, RemoteChannel\n",
    "import Base.show\n",
    "\n",
    "export Rating, MatrixFactorization, Item, User, SVDModel, Solver, SGD, ALS, itembiases, userbiases, fit!, predict, score, learningcurves\n",
    "export SplitMethod, TrainTestSplit, LeaveOneOut, splitcv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Rating\n",
    "\n",
    "User's rating of an item.\n",
    "\"\"\"\n",
    "mutable struct Rating\n",
    "    item::Int64\n",
    "    user::Int64\n",
    "    value::Float64\n",
    "end\n",
    "\n",
    "function Base.show(io::IO, rating::Rating)\n",
    "    fields = fieldnames(Rating)\n",
    "    kwstr = join([\"$(f)=$(getfield(rating, f))\" for f in fields], \", \")\n",
    "    print(io, \"Rating($(kwstr))\")\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Item\n",
    "\n",
    "An Item's weights and bias.\n",
    "\"\"\"\n",
    "mutable struct Item\n",
    "    weights::Vector{Float64}\n",
    "    bias::Float64\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    User\n",
    "\n",
    "A User's weights and bias.\n",
    "\"\"\"\n",
    "mutable struct User\n",
    "    weights::Vector{Float64}\n",
    "    bias::Float64\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Solver\n",
    "\n",
    "Abstract supertype for minimizing algorithms.\n",
    "\"\"\"\n",
    "abstract type Solver end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    SGD <: Solver\n",
    "\n",
    "Stochastic Gradient Descent algorithm.\n",
    "\"\"\"\n",
    "mutable struct SGD <: Solver\n",
    "    nepochs::Int64\n",
    "    lr::Float64\n",
    "    reg::Float64\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    SGD(; <keyword arguments>)\n",
    "\n",
    "# Arguments\n",
    "- `nepochs:::Int64=20`: number of epochs processed during stochastic gradient descent optimization.\n",
    "- `lr::Float64=0.005`: learning rate used during gradient descent optimization.\n",
    "- `reg::Float64=0.02`: regularization parameter used during gradient descent optimization.\n",
    "\"\"\"\n",
    "function SGD(;\n",
    "        nepochs::Int64=10,\n",
    "        lr::Float64=0.001,\n",
    "        reg::Float64=0.0)\n",
    "    SGD(nepochs, lr, reg)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    ALS <: Solver\n",
    "\n",
    "Alternating Least Squares algorithm.\n",
    "\"\"\"\n",
    "mutable struct ALS <: Solver\n",
    "    nepochs::Int64\n",
    "    reg::Float64\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    ALS(; <keyword arguments>)\n",
    "\n",
    "# Arguments\n",
    "- `nepochs:::Int64=20`: number of epochs processed during alternating least squares optimization.\n",
    "- `reg::Float64=0.02`: regularization parameter used during alternating least squares optimization.\n",
    "\"\"\"\n",
    "function ALS(;\n",
    "    nepochs::Int64=10,\n",
    "    reg::Float64=0.0)\n",
    "    ALS(nepochs, reg)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    MatrixFactorization\n",
    "\n",
    "Abstract supertype for matrix factorization based recommender systems models.\n",
    "\"\"\"\n",
    "abstract type MatrixFactorization end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    SVDModel <: MatrixFactorization\n",
    "\n",
    "SVD based recommender systems model.\n",
    "\"\"\"\n",
    "mutable struct SVDModel <: MatrixFactorization\n",
    "    # Factorization\n",
    "    items::Dict{Int64, Item}\n",
    "    users::Dict{Int64, User}\n",
    "    k::Int64\n",
    "    \n",
    "    # Solver\n",
    "    solver::Solver\n",
    "    \n",
    "    # Initialization\n",
    "    mean::Float64\n",
    "    std::Float64\n",
    "    \n",
    "    # Baseline\n",
    "    bias::Float64\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    SVDModel(; <keyword arguments>)\n",
    "\n",
    "# Arguments\n",
    "- `k::Int64=10`: the number of factors.\n",
    "- `mean::Float64=0.0`: mean of the normal distribution used to initialize the factorization matrices.\n",
    "- `std::Float64=1e-4`: standard deviation of the normal distribution used to initialize the factorization matrices.\n",
    "- `nepochs:::Int64=20`: number of epochs processed during stochastic gradient descent optimization.\n",
    "- `lr::Float64=0.005`: learning rate used during gradient descent optimization.\n",
    "- `reg::Float64=0.02`: regularization parameter used during gradient descent optimization.\n",
    "\"\"\"\n",
    "function SVDModel(;\n",
    "        k::Int64=10,\n",
    "        solver::Solver=SGD(),\n",
    "        mean::Float64=0.0,\n",
    "        std::Float64=1e-4)\n",
    "    \n",
    "    items = Dict{Int64, Item}()\n",
    "    users = Dict{Int64, User}()\n",
    "    bias = 0.0\n",
    "    \n",
    "    SVDModel(items,users,k,solver,mean,std,bias)\n",
    "end\n",
    "\n",
    "function Base.show(io::IO, model::SVDModel)\n",
    "    fields = [:k, :mean, :std]\n",
    "    kwstr = join([\"$(f)=$(getfield(model, f))\" for f in fields], \", \")\n",
    "    print(io, \"SVD($(kwstr),...)\")\n",
    "end\n",
    "\n",
    "function User(model::SVDModel)\n",
    "    User(rand(MvNormal(model.k, model.std)), 0.0)\n",
    "    #User(rand(Normal(model.mean, model.std), model.k), 0.0)\n",
    "end\n",
    "\n",
    "function Item(model::SVDModel)\n",
    "    Item(rand(MvNormal(model.k, model.std)), 0.0)\n",
    "    #Item(rand(Normal(model.mean, model.std), model.k), 0.0)\n",
    "end\n",
    "\n",
    "function userbiases(model::SVDModel)\n",
    "    (get(model.users,i,User(model)).bias for i in 1:maximum(keys(model.users)))\n",
    "end\n",
    "\n",
    "function itembiases(model::SVDModel)\n",
    "    (get(model.items,i,Item(model)).bias for i in 1:maximum(keys(model.items)))\n",
    "end\n",
    "\n",
    "\n",
    "function fit!(model::SVDModel, ratings::Vector{Rating}; cb::Union{Function, Nothing}=nothing)\n",
    "    fit!(model, ratings, model.solver; cb=cb)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    fit!(model::SVDModel, ratings::Vector{Ratings}; cb::Union{Function, Nothing}=nothing)\n",
    "\n",
    "Fit the model by optimizing a regularized SSE(Summed Squared Error) through stochastic gradient descent.\n",
    "\n",
    "If passed as the keyword argument `cb`, a callback function will be called at the end of each epoch\n",
    "with arguments `nepoch::Int64` and `cost::Float64`.\n",
    "\"\"\"\n",
    "function fit!(model::SVDModel, ratings::Vector{Rating}, solver::SGD; cb::Union{Function, Nothing}=nothing)\n",
    "    model.bias = mean(r.value for r in ratings)\n",
    "    for r in ratings\n",
    "        if !(r.item in keys(model.items))\n",
    "            model.items[r.item] = Item(model)\n",
    "        end\n",
    "        if !(r.user in keys(model.users))\n",
    "            model.users[r.user] = User(model)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for epoch in 1:solver.nepochs\n",
    "        currentcost = 0\n",
    "        for r in shuffle(ratings)\n",
    "            item = model.items[r.item]\n",
    "            user = model.users[r.user]\n",
    "\n",
    "            e = model.bias + item.bias + user.bias + dot(item.weights, user.weights) - r.value\n",
    "\n",
    "            currentcost += abs2(e)\n",
    "            \n",
    "            item.weights .-= solver.lr .* 2 .* (e .* user.weights .+ solver.reg .* item.weights)\n",
    "            user.weights .-= solver.lr .* 2 .* (e .* item.weights .+ solver.reg .* user.weights)\n",
    "            item.bias -= solver.lr * 2 * (e + solver.reg * item.bias)\n",
    "            user.bias -= solver.lr * 2 * (e + solver.reg * user.bias)\n",
    "        end\n",
    "        \n",
    "        if cb !== nothing\n",
    "            cb(epoch, currentcost)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    predict(model::SVDModel, item::Int64, user::Int64)\n",
    "\n",
    "Predict the rating of an item by a user.\n",
    "\"\"\"\n",
    "function predict(model::SVDModel, item::Int64, user::Int64)\n",
    "    item = get(model.items, item, Item(zeros(Float64, model.k), 0.0))\n",
    "    user = get(model.users, user, User(zeros(Float64, model.k), 0.0))\n",
    "\n",
    "    model.bias + item.bias + user.bias + dot(item.weights, user.weights)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    score(model::SVDModel, ratings::Vector{Rating})\n",
    "\n",
    "Compute the score of the fitted model using SSE(Summed Squared Error).\n",
    "\"\"\"\n",
    "function score(model::SVDModel, ratings::Vector{Rating})\n",
    "    sum(abs2, (predict(model, r.item, r.user) - r.value) for r in ratings)\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    learningcurves(model::SVDModel, train::Vector{Rating}, test::Vector{Rating}, step::Int64=1; cb::Union{Function, Nothing}=nothing)\n",
    "\n",
    "Successively compute the train and test scores necessary to plot the learning curves of the model.\n",
    "\"\"\"\n",
    "function learningcurves(model::SVDModel, train::Vector{Rating}, test::Vector{Rating}, step::Int64=1; cb::Union{Function, Nothing}=nothing)\n",
    "    sizes = collect(1:step:length(train))\n",
    "    trainscores = SharedArray{Float64}(length(sizes))\n",
    "    testscores = SharedArray{Float64}(length(sizes))\n",
    "    \n",
    "    done = RemoteChannel(() -> Channel{Bool}(32))\n",
    "\n",
    "    @distributed for (i,s) in collect(enumerate(sizes))\n",
    "        m = deepcopy(model)\n",
    "        fit!(m, train[1:s])\n",
    "        trainscores[i] = score(m, train[1:s])\n",
    "        testscores[i] = score(m, test)\n",
    "        put!(done, true)\n",
    "    end\n",
    "    \n",
    "    for i in 1:length(sizes)\n",
    "        take!(done)\n",
    "        if cb !== nothing\n",
    "            cb(i, length(sizes))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return (sizes, trainscores, testscores)\n",
    "end\n",
    "\n",
    "# BEGIN: ModelSelection module\n",
    "\"\"\"\n",
    "    SplitMethod\n",
    "\n",
    "Abstract supertype for dataset splitting methods.\n",
    "\"\"\"\n",
    "abstract type SplitMethod end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    TrainTestSplit <: SplitMethod\n",
    "\n",
    "Split a vector of ratings into a training and a test set, according to a percentage ratio.\n",
    "\"\"\"\n",
    "mutable struct TrainTestSplit <: SplitMethod\n",
    "    ratio::Float64\n",
    "    shuffle::Bool\n",
    "    rng\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    TrainTestSplit(ratio::Float64; shuffle::Bool=false, rng=GLOBAL_RNG)\n",
    "\n",
    "Split a vector of ratings into a training and a test set, according to a percentage ratio.\n",
    "\n",
    "# Arguments\n",
    "- `ratio::Float64`: the percentage of ratings to put in training set.\n",
    "- `shuffle::Bool=false`: whether to randomly shuffle the ratings before splitting or not.\n",
    "- `rng=GLOBAL_RNG`: random number generator to shuffle with.\n",
    "\"\"\"\n",
    "function TrainTestSplit(ratio::Float64; shuffle::Bool=false, rng=GLOBAL_RNG)\n",
    "    TrainTestSplit(ratio, shuffle, rng)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    split(method::TrainTestSplit, ratings::Vector{Rating})::NTuple{2, Vector{Rating}}\n",
    "\n",
    "Split a vector of ratings into a training and a test set, according to a percentage ratio.\n",
    "\"\"\"\n",
    "function splitcv(method::TrainTestSplit, ratings::Vector{Rating})::NTuple{2, Vector{Rating}}\n",
    "    if method.shuffle\n",
    "        ratings = shuffle(method.rng, ratings)\n",
    "    end\n",
    "    idx = round(Int, length(ratings) * method.ratio)\n",
    "    return (ratings[1:idx], ratings[idx+1:end])\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LeaveOneOut <: SplitMethod\n",
    "\n",
    "Split a vector of ratings into a training and a test set, each user has exactly one rating in the test set.\n",
    "\"\"\"\n",
    "mutable struct LeaveOneOut <: SplitMethod\n",
    "    minratings::Int64\n",
    "    shuffle::Bool\n",
    "    rng\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LeaveOneOut(;minratings::Int64=0, shuffle::Bool=false, rng=GLOBAL_RNG)\n",
    "\n",
    "Split a vector of ratings into a training and a test set, each user has exactly one rating in the test set.\n",
    "\n",
    "minratings sets the minimum number of ratings for each user in the trainset, others will be discarded.\n",
    "\n",
    "# Arguments\n",
    "- `rng=GLOBAL_RNG`: random number generator to shuffle with.\n",
    "\"\"\"\n",
    "function LeaveOneOut(;minratings::Int64=0, shuffle::Bool=false, rng=GLOBAL_RNG)\n",
    "    LeaveOneOut(minratings, shuffle, rng)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    splitcv(method::LeaveOneOut, ratings::Vector{Rating})::NTuple{2, Vector{Rating}}\n",
    "\n",
    "Split a vector of ratings into a training and a test set, each user has exactly one rating in the test set.\n",
    "\"\"\"\n",
    "function splitcv(method::LeaveOneOut, ratings::Vector{Rating})::NTuple{2, Vector{Rating}}\n",
    "    if method.shuffle\n",
    "        ratings = shuffle(method.rng, ratings)\n",
    "    end\n",
    "    trainset = Rating[]\n",
    "    testset = Rating[]\n",
    "    users = Dict{Int64, NamedTuple{(:count, :done), Tuple{Int64, Bool}}}()\n",
    "    \n",
    "    for r in ratings\n",
    "        user = get!(users, r.user, (count=0, done=false))\n",
    "        users[r.user] = (count=user.count+1, done=user.done)\n",
    "    end\n",
    "    \n",
    "    for r in ratings\n",
    "        user = users[r.user]\n",
    "        if user.count >= method.minratings\n",
    "            if !user.done\n",
    "                push!(testset, r)\n",
    "                users[r.user] = (count=user.count, done=true)\n",
    "            else\n",
    "                push!(trainset, r)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "            \n",
    "    return (trainset, testset)\n",
    "end\n",
    "# END: ModelSelection module\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write module to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write(\"RecommenderSystems.jl\", In[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using .RecommenderSystems, PyCall, Distributed, Plots, IJulia, Random, Statistics, Distributions, SparseArrays, Traceur\n",
    "\n",
    "loadmat = pyimport(\"scipy.io\")[\"loadmat\"]\n",
    "data = loadmat(\"ex8_movies.mat\")\n",
    "Y = convert(Array{Float64}, data[\"Y\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(4)\n",
    "@everywhere push!(LOAD_PATH, \".\")\n",
    "@everywhere workers() using RecommenderSystems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destroy workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit! test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed epoch #100: 123.4150036324268\n",
      "  5.869590 seconds (353.12 k allocations: 95.634 MiB, 1.19% gc time)\n"
     ]
    }
   ],
   "source": [
    "model1 = SVDModel(k=100, solver=SGD(nepochs=100, lr=0.013, reg=0.0))\n",
    "ratings = [Rating(ci.I[1], ci.I[2], Y[ci]) for ci in findall(x->x>0, Y)]\n",
    "shuffle!(ratings)\n",
    "costs = Float64[]\n",
    "@time fit!(model1, ratings, cb=(epoch, cost) -> begin\n",
    "    IJulia.clear_output(true)\n",
    "    println(\"Processed epoch #$(epoch): $(cost)\")\n",
    "    push!(costs, cost)\n",
    "end)\n",
    "\n",
    "#plot(costs, xlabel=\"iterations\", ylabel=\"cost\", legend=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 943)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(model1.items), length(model1.users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(model1, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(ci -> predict(model1, ci.I[1], ci.I[2]), CartesianIndices(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learningcurves test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [Rating(ci.I[1], ci.I[2], Y[ci]) for ci in findall(x->x>0, Y)]\n",
    "trainset, testset = splitcv(TrainTestSplit(0.9, shuffle=true), ratings);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [Rating(ci.I[1], ci.I[2], Y[ci]) for ci in findall(x->x>0, Y)]\n",
    "trainset, testset = splitcv(LeaveOneOut(shuffle=true), ratings);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time let model = SVDModel(k=100, nepochs=100, lr=0.01, reg=0.008)\n",
    "    global sizes, trainscores, testscores = learningcurves(model, trainset, testset, 10000, cb=(index, total) -> begin\n",
    "            IJulia.clear_output(true)\n",
    "            println(\"Trained $(index)/$(total)\")\n",
    "            end)\n",
    "end\n",
    "\n",
    "plot(sizes, trainscores, xlabel=\"number of examples\", ylabel=\"score\", label=\"train score\")\n",
    "plot!(sizes, testscores, label=\"test score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LinearAlgebra, SharedArrays, SparseArrays\n",
    "function als!(model::SVDModel, ratings::Vector{Rating}; cb::Union{Function, Nothing}=nothing)\n",
    "    R = dropzeros(sparse([r.item for r in ratings], [r.user for r in ratings], [r.value for r in ratings]))\n",
    "    nitems, nusers = R.m, R.n\n",
    "    \n",
    "    rateditems, ratingusers, rates = findnz(R)\n",
    "    for i in Set(rateditems)\n",
    "        model.items[i] = Item(model)\n",
    "    end\n",
    "    for u in Set(ratingusers)\n",
    "        model.users[u] = User(model)\n",
    "    end\n",
    "    \n",
    "    model.bias = mean(nonzeros(R))\n",
    "    bi = SharedArray{Float64}(nitems)\n",
    "    bu = SharedArray{Float64}(nusers)\n",
    "    \n",
    "    P = SharedArray{Float64}(nitems, model.k)\n",
    "    P .= rand(Normal(model.mean, model.std), nitems, model.k)\n",
    "    Q = SharedArray{Float64}(nusers, model.k)\n",
    "    Q .= rand(Normal(model.mean, model.std), nusers, model.k)\n",
    "    \n",
    "    function updatefactors()\n",
    "        for i in Set(rateditems)\n",
    "            model.items[i] = Item(P[i,:], bi[i])\n",
    "        end\n",
    "        for u in Set(ratingusers)\n",
    "            model.users[u]  = User(Q[u,:], bu[u])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    R_mu = R .- model.bias\n",
    "    rtol = sqrt(eps(real(float(one(Float64)))))\n",
    "    \n",
    "    for epoch in 1:model.nepochs\n",
    "        P_biased = [ones(nitems) P]\n",
    "        R_mu_bi = R_mu .- bi\n",
    "        @sync @distributed for u in 1:nusers\n",
    "            rated_items_indices = R[:, u].nzind\n",
    "            P_biased_truncated = P_biased[rated_items_indices, :]\n",
    "            A = P_biased_truncated' * P_biased_truncated + model.reg * I\n",
    "            b = P_biased_truncated' * R_mu_bi[rated_items_indices, u]\n",
    "            x = pinv(A, rtol) * b\n",
    "            bu[u], Q[u,:] = x[1], x[2:end]\n",
    "        end\n",
    "        \n",
    "        Q_biased = [ones(nusers) Q]\n",
    "        R_mu_bu = R_mu .- bu'\n",
    "        @sync @distributed for i in 1:nitems\n",
    "            rating_users_indices = R[i, :].nzind\n",
    "            Q_biased_truncated = Q_biased[rating_users_indices, :]\n",
    "            A = Q_biased_truncated' * Q_biased_truncated + model.reg * I\n",
    "            b = Q_biased_truncated' * R_mu_bu[i, rating_users_indices]\n",
    "            x = pinv(A, rtol) * b\n",
    "            bi[i], P[i,:] = x[1], x[2:end]\n",
    "        end\n",
    "        \n",
    "        if cb !== nothing\n",
    "            updatefactors()\n",
    "            currentcost = score(model, ratings)\n",
    "            cb(epoch, currentcost)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    updatefactors()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = Float64[]\n",
    "model2 = SVDModel(k=100, nepochs=20, lr=0.01, reg=0.0)\n",
    "ratings = [Rating(ci.I[1], ci.I[2], Y[ci]) for ci in findall(x->x>0, Y)]\n",
    "@time als!(model2, ratings, cb=(epoch, cost) -> begin\n",
    "        IJulia.clear_output(true)\n",
    "        println(\"Processed epoch #$(epoch): $(cost)\")\n",
    "        push!(costs, cost)\n",
    "        end)\n",
    "\n",
    "plot(costs, xlabel=\"iterations\", ylabel=\"cost\", legend=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using LinearAlgebra, SharedArrays, SparseArrays\n",
    "function veals!(model::SVDModel, ratings::Vector{Rating}; cb::Union{Function, Nothing}=nothing)\n",
    "    R = dropzeros(sparse([r.user for r in ratings], [r.item for r in ratings], [r.value for r in ratings]))\n",
    "    nusers, nitems = R.m, R.n\n",
    "    \n",
    "    ratingusers, rateditems, rates = findnz(R)\n",
    "    for i in Set(rateditems)\n",
    "        model.items[i] = Item(model)\n",
    "    end\n",
    "    for u in Set(ratingusers)\n",
    "        model.users[u] = User(model)\n",
    "    end\n",
    "    \n",
    "    P = SharedArray{Float64}(nusers, model.k)\n",
    "    P .= rand(Normal(model.mean, model.std), nusers, model.k)\n",
    "    Q = SharedArray{Float64}(nitems, model.k)\n",
    "    Q .= rand(Normal(model.mean, model.std), nitems, model.k)\n",
    "    \n",
    "    Predictions = SharedArray{Float64}(nusers, nitems)\n",
    "    Predictions_minus = SharedArray{Float64}(nusers, nitems)\n",
    "    \n",
    "    for r in ratings\n",
    "        Predictions[r.user, r.item] = P[r.user,:]'*Q[r.item,:]\n",
    "    end\n",
    "    \n",
    "    W = sparse(ratingusers, rateditems, ones(length(ratingusers)))\n",
    "    \n",
    "    function updatefactors()\n",
    "        for i in Set(rateditems)\n",
    "            model.items[i] = Item(Q[i,:], 0.0)\n",
    "        end\n",
    "        for u in Set(ratingusers)\n",
    "            model.users[u]  = User(P[u,:], 0.0)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for epoch in 1:model.nepochs\n",
    "        @sync @distributed for u in 1:nusers\n",
    "            for f in 1:model.k\n",
    "                Predictions_minus[u, :] = Predictions[u, :] .- P[u, f] .* Q[:, f]\n",
    "                P[u, f] = sum(i->(Predictions[u,i] - Predictions_minus[u,i]) * W[u,i] * Q[i,f], 1:nitems) / sum(i->W[u,i] * Q[i,f]^2 + model.reg, 1:nitems)\n",
    "                Predictions[u, :] = Predictions_minus[u, :] .+ P[u, f] .* Q[:, f]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        @sync @distributed for i in 1:nitems\n",
    "            for f in 1:model.k\n",
    "                Predictions_minus[:, i] = Predictions[:, i] .- P[:, f] .* Q[i, f]\n",
    "                Q[i, f] = sum(u->(Predictions[u,i] - Predictions_minus[u,i]) * W[u,i] * P[u,f], 1:nusers) / sum(u->W[u,i] * P[u,f]^2 + model.reg, 1:nusers)\n",
    "                Predictions[:, i] = Predictions_minus[:, i] .+ P[:, f] .* Q[i, f]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if cb !== nothing\n",
    "            updatefactors()\n",
    "            currentcost = score(model, ratings)\n",
    "            cb(epoch, currentcost)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    updatefactors()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(ci -> predict(model2, ci.I[1], ci.I[2]), CartesianIndices(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder\n",
    "\n",
    "use `collect(enumerate` with `@distributed`!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Find out with score is more important in learning curves than in gradient descent graph !!!\n",
    "- Implement ALS without biases, à la NETFLIX.\n",
    "- Implement K-folds\n",
    "- Validation curves function\n",
    "- Random CV Search Function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
